{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put this just below the imports before calling main\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='training')\n",
    "parser.add_argument('-node', default=None, help='node to use, in format boole-n021')\n",
    "parser.add_argument('-model_dir', default=None, help='the folder containing the preprocessed data')\n",
    "parser.add_argument('-gpu', default=0, help='which gpu to use')\n",
    "opts = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = 'boole-n021'\n",
    "gpu = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sigopt import Connection\n",
    "conn = Connection(client_token=\"IFAQZABYDOBABXMSZYAWSYKHYSONHNPEACATCSCCIDXDQFLG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = '27604'\n",
    "# print(conn.experiments(experiment_id).suggestions().fetch(\n",
    "#     state=\"open\",\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "preprocessed_dir = glob.glob('/home/henrye/projects/E2E/experiments/*' + experiment_id + '*')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestion({\n",
      "  \"assignments\": {\n",
      "    \"x\": 0.789986936091864,\n",
      "    \"y\": 0.03618364763806858\n",
      "  },\n",
      "  \"created\": 1509290838,\n",
      "  \"experiment\": \"27604\",\n",
      "  \"fold\": null,\n",
      "  \"fold_index\": null,\n",
      "  \"id\": \"12835705\",\n",
      "  \"metadata\": null,\n",
      "  \"object\": \"suggestion\",\n",
      "  \"state\": \"open\"\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "suggestion = conn.experiments(experiment_id).suggestions().create()\n",
    "print(suggestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_opts = ' '.join('{} {}'.format(key, value) for key, value in suggestion.assignments.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/henrye/projects/E2E/experiments/baseline-test-27604-2017_10_29__15_03'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_dir[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_output = subprocess.run(['bash',\n",
    "    '/home/henrye/projects/E2E/bash_training_scripts/start_training_template.sh',\n",
    "    '-n', node,\n",
    "    '-g', gpu,\n",
    "    '-p', preprocessed_dir,\n",
    "    '-t', training_opts],\n",
    "              stdout=subprocess.PIPE)\n",
    "training_output = training_output.stdout.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/henrye/projects/E2E/experiments/baseline-test-27604-2017_10_29__15_03/checkpoints-boole-n021-0-2017_10_29__16_51\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    checkpoint_dir = re.search('the checkpoint directory is (.*) end transmission', \\\n",
    "                               training_output).group(1)\n",
    "except AttributeError:\n",
    "    checkpoint_dir = ''\n",
    "    print('no checkpoint found? should we quit or skip to next iteration')\n",
    "#     quit()\n",
    "print(checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_opts = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_output_full = subprocess.run(['bash',\n",
    "    '/home/henrye/projects/E2E/bash_training_scripts/evaluate_model_checkpoint.sh',\n",
    "    '-n', node,\n",
    "    '-g', gpu,\n",
    "    '-c', checkpoint_dir,\n",
    "    '-e', evaluation_opts],\n",
    "              stdout=subprocess.PIPE)\n",
    "evaluation_output = evaluation_output_full.stdout.decode()\n",
    "# evaluation_output_full.args\n",
    "# take the list of strings and join on ' '.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last login: Sun Oct 29 19:04:16 2017 from boole-n001.cluster\r",
      "\r\n",
      " _                 _\r\n",
      "| |__   ___   ___ | | ___\r\n",
      "| '_ \\ / _ \\ / _ \\| |/ _ \\\r\n",
      "| |_) | (_) | (_) | |  __/\r\n",
      "|_.__/ \\___/ \\___/|_|\\___|\r\n",
      "\r\n",
      "    echo \"the generated outputs directory is /home/henrye/projects/E2E/experiments/baseline-test-27604-2017_10_29__15_03/checkpoints-boole-n021-0-2017_10_29__16_51/generated-outputs-boole-n021-gpu_0-2017_10_29__19_05 end transmission\"\r\n",
      "    for model_checkpoint in /home/henrye/projects/E2E/experiments/baseline-test-27604-2017_10_29__15_03/checkpoints-boole-n021-0-2017_10_29__16_51/checkpoint*e{8..9}.pt\r\n",
      "        do\r\n",
      "            if [ ! -f $model_checkpoint ]; then\r\n",
      "                echo \"file not found\"\r\n",
      "                continue\r\n",
      "            fi\r\n",
      "            source activate pytorch\r\n",
      "            cd ~/downloads/OpenNMT-py\r\n",
      "            # TODO figure out how to do some regex on the file name to simplify it\r\n",
      "            model_checkpoint_file_name=$(basename \"$model_checkpoint\")\r\n",
      "            # TODO possibly check for tmp generated files in generated_outputs_dir\r\n",
      "            for source_file in /home/henrye/projects/E2E/experiments/baseline-test-27604-2017_10_29__15_03/{dev*,test*}\r\n",
      "                do\r\n",
      "                    source_file_name=$(basename \"$source_file\")\r\n",
      "                    output_file_name=$source_file_name-$model_checkpoint_file_name\r\n",
      "                    echo $output_file_name\r\n",
      "                    # generate using the source_file as input and output to\r\n",
      "                    # output using the model checkpoint\r\n",
      "\r\n",
      "                    # Running tracer output for testing\r\n",
      "                    touch /home/henrye/projects/E2E/experiments/baseline-test-27604-2017_10_29__15_03/checkpoints-boole-n021-0-2017_10_29__16_51/generated-outputs-boole-n021-gpu_0-2017_10_29__19_05/$output_file_name\r\n",
      "\r\n",
      "                    # python translate.py                     #     -model $model_checkpoint                     #     -src $source_file                     #     -output /home/henrye/projects/E2E/experiments/baseline-test-27604-2017_10_29__15_03/checkpoints-boole-n021-0-2017_10_29__16_51/generated-outputs-boole-n021-gpu_0-2017_10_29__19_05/$output_file_name                     #     -gpu 0                     #     -max_sent_length 500                     #     -beam_size 2                     #     -batch_size 1                     #     -n_best 1\r\n",
      "                    #     # TODO return beam_size value back to 30 \r\n",
      "                done\r\n",
      "            # Evaluate the devset file using measure_scores.py and pipe the \r\n",
      "            # output to grep: | grep -P -o \"= \\K.*\"\r\n",
      "                # this will be /home/henrye/projects/E2E/experiments/baseline-test-27604-2017_10_29__15_03/checkpoints-boole-n021-0-2017_10_29__16_51/generated-outputs-boole-n021-gpu_0-2017_10_29__19_05/dev*$model_checkpoint_file_name\r\n",
      "            cd /home/henrye/downloads/e2e-metrics\r\n",
      "            # e2e metrics run on python 2 so we switch to theano env\r\n",
      "            source activate theano\r\n",
      "            # We assume that the devset-target.grouped files will never change\r\n",
      "            # Trying out two different thing to make sure the command is \r\n",
      "            # executed correctly \r\n",
      "            # https://stackoverflow.com/questions/32477571/using-backticks-over-ssh-in-a-script\r\n",
      "            # https://stackoverflow.com/questions/4651437/how-to-set-a-variable-to-the-output-from-a-command-in-bash\r\n",
      "\r\n",
      "            # Running tracer output for testing\r\n",
      "            checkpoint_scores=\"BLEU,0.6537,NIST,7.7660,METEOR,0.4819,ROUGE_L,0.7319,CIDEr,2.3479\"\r\n",
      "\r\n",
      "            # checkpoint_scores=`python measure_scores.py             #     ~/projects/E2E/data/devset-target.grouped             #     /home/henrye/projects/E2E/experiments/baseline-test-27604-2017_10_29__15_03/checkpoints-boole-n021-0-2017_10_29__16_51/generated-outputs-boole-n021-gpu_0-2017_10_29__19_05/dev*$model_checkpoint_file_name`\r\n",
      "            # checkpoint_scores=`echo $checkpoint_scores | grep -P -o \"= \\K.*\"`\r\n",
      "            # checkpoint_scores=${checkpoint_scores//\\ /,}\r\n",
      "            # checkpoint_scores=${checkpoint_scores//:/}\r\n",
      "            # echo this checkpoint scores are $checkpoint_scores-$model_checkpoint end transmission\r\n",
      "            # Another for loop to add the scores to the end of the file name            \r\n",
      "            for generated_outputs in /home/henrye/projects/E2E/experime\u001b]0;henrye@boole-n021:~\u0007[henrye@boole-n021 ~]$     echo \"the generated outputs directory is /home/henrye \r",
      "/projects/E2E/experiments/baseline-test-27604-2017_10_29__15_03/checkpoints-bool \r",
      "e-n021-0-2017_10_29__16_51/generated-outputs-boole-n021-gpu_0-2017_10_29__19_05  \r",
      "end transmission\"\r\n",
      "\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\u0007\r\n",
      "the generated outputs directory is /home/henrye/projects/E2E/experiments/baseline-test-27604-2017_10_29__15_03/checkpoints-boole-n021-0-2017_10_29__16_51/generated-outputs-boole-n021-gpu_0-2017_10_29__19_05 end transmission\r\n",
      "\u001b]0;henrye@boole-n021:~\u0007[henrye@boole-n021 ~]$     for model_checkpoint in /home/henrye/projects/E2E/exp \r",
      "eriments/baseline-test-27604-2017_10_29__15_03/checkpoints-boole-n021-0-2017_10_ \r",
      "29__16_51/checkpoint*e{8..9}.pt\r\n",
      ">         do\r\n",
      ">             if [ ! -f $model_checkpoint ]; then\r\n",
      ">                 echo \"file not found\"\r\n",
      ">                 continue\r\n",
      ">             fi\r\n",
      ">             source activate pytorch\r\n",
      ">             cd ~/downloads/OpenNMT-py\r\n",
      ">             # TODO figure out how to do some regex on the file name to simplif \r",
      "y it\r\n",
      ">             model_checkpoint_file_name=$(basename \"$model_checkpoint\")\r\n",
      ">             # TODO possibly check for tmp generated files in generated_outputs \r",
      "_dir\r\n",
      ">             for source_file in /home/henrye/projects/E2E/experiments/baseline- \r",
      "test-27604-2017_10_29__15_03/{dev*,test*}\r\n",
      ">                 do\r\n",
      ">                     source_file_name=$(basename \"$source_file\")\r\n",
      ">                     output_file_name=$source_file_name-$model_checkpoint_file_ \r",
      "name\r\n",
      ">                     echo $output_file_name\r\n",
      ">                     # generate using the source_file as input and output to\r\n",
      ">                     # output using the model checkpoint\r\n",
      "> \r\n",
      ">                     # Running tracer output for testing\r\n",
      ">                     touch /home/henrye/projects/E2E/experiments/baseline-test- \r",
      "27604-2017_10_29__15_03/checkpoints-boole-n021-0-2017_10_29__16_51/generated-out \r",
      "puts-boole-n021-gpu_0-2017_10_29__19_05/$output_file_name\r\n",
      "> \r\n",
      ">                     # python translate.py                     #     -model $mo \r",
      "del_checkpoint                     #     -src $source_file                     # \r",
      "     -output /home/henrye/projects/E2E/experiments/baseline-test-27604-2017_10_2 \r",
      "9__15_03/checkpoints-boole-n021-0-2017_10_29__16_51/generated-outputs-boole-n021 \r",
      "-gpu_0-2017_10_29__19_05/$output_file_name                     #     -gpu 0      \r",
      "                #     -max_sent_length 500                     #     -beam_size  \r",
      "2                     #     -batch_size 1                     #     -n_best 1\r\n",
      ">                     #     # TODO return beam_size value back to 30 \r\n",
      ">                 done\r\n",
      ">             # Evaluate the devset file using measure_scores.py and pipe the \r\n",
      ">             # output to grep: | grep -P -o \"= \\K.*\"\r\n",
      ">                 # this will be /home/henrye/projects/E2E/experiments/baseline- \r",
      "test-27604-2017_10_29__15_03/checkpoints-boole-n021-0-2017_10_29__16_51/generate \r",
      "d-outputs-boole-n021-gpu_0-2017_10_29__19_05/dev*$model_checkpoint_file_name\r\n",
      ">             cd /home/henrye/downloads/e2e-metrics\r\n",
      ">             # e2e metrics run on python 2 so we switch to theano env\r\n",
      ">             source activate theano\r\n",
      ">             # We assume that the devset-target.grouped files will never change \r",
      "\u001b[A\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[C\u001b[Ke\r\n",
      ">             # Trying out two different thing to make sure the command is \r\n",
      ">             # executed correctly \r\n",
      ">             # https://stackoverflow.com/questions/32477571/using-backticks-ove \r",
      "r-ssh-in-a-script\r\n",
      ">             # https://stackoverflow.com/questions/4651437/how-to-set-a-variabl \r",
      "e-to-the-output-from-a-command-in-bash\r\n",
      "> \r\n",
      ">             # Running tracer output for testing\r\n",
      ">             checkpoint_scores=\"BLEU,0.6537,NIST,7.7660,METEOR,0.4819,ROUGE_L,0 \r",
      ".7319,CIDEr,2.3479\"\r\n",
      "> \r\n",
      ">             # checkpoint_scores=`python measure_scores.py             #     ~/ \r",
      "projects/E2E/data/devset-target.grouped             #     /home/henrye/projects/ \r",
      "E2E/experiments/baseline-test-27604-2017_10_29__15_03/checkpoints-boole-n021-0-2 \r",
      "017_10_29__16_51/generated-outputs-boole-n021-gpu_0-2017_10_29__19_05/dev*$model \r",
      "_checkpoint_file_name`\r\n",
      ">             # checkpoint_scores=`echo $checkpoint_scores | grep -P -o \"= \\K.*\" \r",
      "`\r\n",
      ">             # checkpoint_scores=${checkpoint_scores//\\ /,}\r\n",
      ">             # checkpoint_scores=${checkpoint_scores//:/}\r\n",
      ">             # echo this checkpoint scores are $checkpoint_scores-$model_checkp \r",
      "oint end transmission\r\n",
      ">             # Another for loop to add the scores to the end of the file name   \r",
      "          \r\n",
      ">             for generated_outputs in /home/henrye/projects/E2E/experiments/bas \r",
      "eline-test-27604-2017_10_29__15_03/checkpoints-boole-n021-0-2017_10_29__16_51/ge \r",
      "nerated-outputs-boole-n021-gpu_0-2017_10_29__19_05/{dev,test}*$model_checkpoint_ \r",
      "file_name\r\n",
      ">                 do\r\n",
      ">                     mv $generated_outpu\r\n",
      ">                 done\r\n",
      ">         done\r\n",
      "devset-source.tok.unique-checkpoint_e8.pt\r\n",
      "test_e2e-source.tok-checkpoint_e8.pt\r\n",
      "mv: missing file operand\r\n",
      "Try 'mv --help' for more information.\r\n",
      "mv: missing file operand\r\n",
      "Try 'mv --help' for more information.\r\n",
      "file not found\r\n",
      "\u001b]0;henrye@boole-n021:~/downloads/e2e-metrics\u0007(theano) [henrye@boole-n021 e2e-metrics]$     exit\r\n",
      "logout\r\n",
      "\n",
      "/home/henrye/projects/E2E/experiments/baseline-test-27604-2017_10_29__15_03/checkpoints-boole-n021-0-2017_10_29__16_51/generated-outputs-boole-n021-gpu_0-2017_10_29__19_05\n"
     ]
    }
   ],
   "source": [
    "print(evaluation_output)\n",
    "generated_outputs_directory = re.search('the generated outputs directory is (.*) end transmission', \\\n",
    "                               evaluation_output).group(1)\n",
    "print(generated_outputs_directory)\n",
    "# output_scores = re.search('this checkpoint scores are (.*) end transmission', \\\n",
    "#                                evaluation_output).group(1)\n",
    "# print(output_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$checkpoint_scores-$model_checkpoint'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BLEU,0.7637,NIST,7.7660,METEOR,0.4819,ROUGE_L,0.7319,CIDEr,2.3479',\n",
       " 'BLEU,0.6637,NIST,7.7660,METEOR,0.4819,ROUGE_L,0.7319,CIDEr,2.3479',\n",
       " 'BLEU,0.5637,NIST,8.7660,METEOR,0.4819,ROUGE_L,0.7319,CIDEr,2.3479']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_strings = ['BLEU,0.7637,NIST,7.7660,METEOR,0.4819,ROUGE_L,0.7319,CIDEr,2.3479',\n",
    "                   'BLEU,0.5637,NIST,8.7660,METEOR,0.4819,ROUGE_L,0.7319,CIDEr,2.3479',\n",
    "                  'BLEU,0.6637,NIST,7.7660,METEOR,0.4819,ROUGE_L,0.7319,CIDEr,2.3479',]\n",
    "sorted(list_of_strings, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lol'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "this = defaultdict(lambda:'lol')\n",
    "this['whwhwh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_list_of_dicts_of_parameters = \\\n",
    "    {\n",
    "        'baseline':\n",
    "            [\n",
    "                {\n",
    "                    'name': '-word_vec_dim',\n",
    "                    'type': 'int',\n",
    "                    'bounds': \n",
    "                    {\n",
    "                        'min': 100.0,\n",
    "                        'max': 1000.0\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "    }\n",
    "\n",
    "test_dict = defaultdict(lambda:'lol', dict_of_list_of_dicts_of_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bounds': {'max': 1000.0, 'min': 100.0},\n",
       "  'name': '-word_vec_dim',\n",
       "  'type': 'int'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict['baseline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run `pip install sigopt` to download the python API client\n",
    "from sigopt import Connection\n",
    "from sigopt.examples import franke_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = Connection(client_token=\"IFAQZABYDOBABXMSZYAWSYKHYSONHNPEACATCSCCIDXDQFLG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created experiment: https://sigopt.com/experiment/27604\n"
     ]
    }
   ],
   "source": [
    "\n",
    "experiment = conn.experiments().create(\n",
    "    name='Franke Optimization (Python)',\n",
    "    parameters=[\n",
    "        dict(name='x', type='double', bounds=dict(min=0.0, max=1.0)),\n",
    "        dict(name='y', type='double', bounds=dict(min=0.0, max=1.0)),\n",
    "    ],\n",
    ")\n",
    "print(\"Created experiment: https://sigopt.com/experiment/\" + experiment.id)\n",
    "\n",
    "# Evaluate your model with the suggested parameter assignments\n",
    "# Franke function - http://www.sfu.ca/~ssurjano/franke2d.html\n",
    "def evaluate_model(assignments):\n",
    "    return franke_function(assignments['x'], assignments['y'])\n",
    "\n",
    "# Run the Optimization Loop between 10x - 20x the number of parameters\n",
    "for _ in range(30):\n",
    "    suggestion = conn.experiments(experiment.id).suggestions().create()\n",
    "    value = evaluate_model(suggestion.assignments)\n",
    "    conn.experiments(experiment.id).observations().create(\n",
    "        suggestion=suggestion.id,\n",
    "        value=value,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestion = conn.experiments(27604).suggestions().create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suggestion({\n",
       "  \"assignments\": {\n",
       "    \"x\": 0.9439681426019584,\n",
       "    \"y\": 0.17154101101444252\n",
       "  },\n",
       "  \"created\": 1509270406,\n",
       "  \"experiment\": \"27604\",\n",
       "  \"fold\": null,\n",
       "  \"fold_index\": null,\n",
       "  \"id\": \"12833147\",\n",
       "  \"metadata\": null,\n",
       "  \"object\": \"suggestion\",\n",
       "  \"state\": \"open\"\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we probably don't have to create the experiment from scratch necessarily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can track your experiment at https://sigopt.com/experiment/27604\n"
     ]
    }
   ],
   "source": [
    "print(\"You can track your experiment at https://sigopt.com/experiment/{0}\".format(experiment.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experiment({\n",
       "  \"client\": \"6526\",\n",
       "  \"conditionals\": [],\n",
       "  \"created\": 1509026516,\n",
       "  \"development\": false,\n",
       "  \"folds\": null,\n",
       "  \"id\": \"27604\",\n",
       "  \"linear_constraints\": [],\n",
       "  \"metadata\": null,\n",
       "  \"metric\": {\n",
       "    \"name\": null,\n",
       "    \"object\": \"metric\",\n",
       "    \"value_baseline\": null\n",
       "  },\n",
       "  \"metrics\": [\n",
       "    {\n",
       "      \"name\": null,\n",
       "      \"object\": \"metric\",\n",
       "      \"value_baseline\": null\n",
       "    }\n",
       "  ],\n",
       "  \"name\": \"Franke Optimization (Python)\",\n",
       "  \"num_solutions\": 1,\n",
       "  \"object\": \"experiment\",\n",
       "  \"observation_budget\": null,\n",
       "  \"parallel_bandwidth\": 1,\n",
       "  \"parameters\": [\n",
       "    {\n",
       "      \"bounds\": {\n",
       "        \"max\": 1.0,\n",
       "        \"min\": 0.0,\n",
       "        \"object\": \"bounds\"\n",
       "      },\n",
       "      \"categorical_values\": null,\n",
       "      \"conditions\": {},\n",
       "      \"default_value\": null,\n",
       "      \"name\": \"x\",\n",
       "      \"object\": \"parameter\",\n",
       "      \"precision\": null,\n",
       "      \"tunable\": true,\n",
       "      \"type\": \"double\"\n",
       "    },\n",
       "    {\n",
       "      \"bounds\": {\n",
       "        \"max\": 1.0,\n",
       "        \"min\": 0.0,\n",
       "        \"object\": \"bounds\"\n",
       "      },\n",
       "      \"categorical_values\": null,\n",
       "      \"conditions\": {},\n",
       "      \"default_value\": null,\n",
       "      \"name\": \"y\",\n",
       "      \"object\": \"parameter\",\n",
       "      \"precision\": null,\n",
       "      \"tunable\": true,\n",
       "      \"type\": \"double\"\n",
       "    }\n",
       "  ],\n",
       "  \"progress\": {\n",
       "    \"best_observation\": null,\n",
       "    \"first_observation\": null,\n",
       "    \"last_observation\": null,\n",
       "    \"object\": \"progress\",\n",
       "    \"observation_count\": 0\n",
       "  },\n",
       "  \"state\": \"active\",\n",
       "  \"type\": \"offline\",\n",
       "  \"user\": 2324\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'clients',\n",
       " 'experiments',\n",
       " 'impl',\n",
       " 'set_api_url',\n",
       " 'set_proxies',\n",
       " 'set_verify_ssl_certs']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
